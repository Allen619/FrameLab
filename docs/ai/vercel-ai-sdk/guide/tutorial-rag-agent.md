---
title: å®æˆ˜ï¼šRAG Agent
description: ä»é›¶æ„å»ºä¸€ä¸ªåŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰çš„æ™ºèƒ½é—®ç­” Agentï¼ŒåŒ…æ‹¬æ–‡æ¡£åµŒå…¥ã€å‘é‡å­˜å‚¨ã€è¯­ä¹‰æ£€ç´¢å’Œä¸Šä¸‹æ–‡å¢å¼ºç”Ÿæˆã€‚
---

# å®æˆ˜ï¼šRAG Agent

æœ¬æ•™ç¨‹å°†æ‰‹æŠŠæ‰‹å¸¦ä½ æ„å»ºä¸€ä¸ª RAGï¼ˆRetrieval-Augmented Generationï¼Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰Agentã€‚RAG é€šè¿‡åœ¨ç”Ÿæˆå›ç­”å‰æ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼Œè®© LLM èƒ½å¤ŸåŸºäºä½ çš„ç§æœ‰çŸ¥è¯†åº“è¿›è¡Œå‡†ç¡®å›ç­”ã€‚

[ğŸ”— AI SDK RAG èŠå¤©æœºå™¨äººæŒ‡å—](https://ai-sdk.dev/cookbook/guides/rag-chatbot){target="_blank" rel="noopener"}

## ä»€ä¹ˆæ˜¯ RAG

::: tip å‰ç«¯ç±»æ¯”
RAG å°±åƒç»™æœç´¢å¼•æ“åŠ ä¸Šäº† AI ç†è§£èƒ½åŠ›ã€‚ä¼ ç»Ÿæœç´¢è¿”å›æ–‡æ¡£åˆ—è¡¨è®©ç”¨æˆ·è‡ªå·±é˜…è¯»ï¼ŒRAG åˆ™æ˜¯å…ˆæœç´¢ç›¸å…³æ–‡æ¡£ï¼Œå†è®© AI åŸºäºè¿™äº›æ–‡æ¡£ç”Ÿæˆç²¾å‡†å›ç­” â€”â€” ç±»ä¼¼äº Google çš„ AI Overviewã€‚
:::

RAG çš„ä¸‰ä¸ªæ ¸å¿ƒæ­¥éª¤ï¼š

1. **åµŒå…¥ï¼ˆEmbedï¼‰** â€” å°†æ–‡æ¡£è½¬æ¢ä¸ºå‘é‡è¡¨ç¤º
2. **æ£€ç´¢ï¼ˆRetrieveï¼‰** â€” æ ¹æ®ç”¨æˆ·æŸ¥è¯¢æ‰¾åˆ°æœ€ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µ
3. **ç”Ÿæˆï¼ˆGenerateï¼‰** â€” å°†æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡æä¾›ç»™ LLM ç”Ÿæˆå›ç­”

```mermaid
flowchart LR
    A[ç”¨æˆ·é—®é¢˜] --> B[ç”ŸæˆæŸ¥è¯¢å‘é‡]
    B --> C[å‘é‡ç›¸ä¼¼åº¦æœç´¢]
    C --> D[è¿”å›ç›¸å…³æ–‡æ¡£ç‰‡æ®µ]
    D --> E[æ‹¼æ¥ä¸Šä¸‹æ–‡ + é—®é¢˜]
    E --> F[LLM ç”Ÿæˆå›ç­”]
```

## ç¯å¢ƒå‡†å¤‡

```bash
npm install ai @ai-sdk/openai zod
```

## ç¬¬ä¸€æ­¥ï¼šæ–‡æ¡£åµŒå…¥

å°†æ–‡æ¡£åˆ‡åˆ†ä¸ºç‰‡æ®µï¼Œå¹¶ç”Ÿæˆæ¯ä¸ªç‰‡æ®µçš„å‘é‡è¡¨ç¤ºï¼š

```typescript
import { embed, embedMany } from 'ai'

// å°†æ–‡æœ¬åˆ‡åˆ†ä¸ºç‰‡æ®µ
function generateChunks(input: string): string[] {
  return input
    .trim()
    .split('.')
    .map((chunk) => chunk.trim())
    .filter((chunk) => chunk.length > 0)
}

// æ‰¹é‡ç”ŸæˆåµŒå…¥å‘é‡
async function generateEmbeddings(
  text: string,
): Promise<Array<{ content: string; embedding: number[] }>> {
  const chunks = generateChunks(text)

  const { embeddings } = await embedMany({
    model: 'openai/text-embedding-3-small',
    values: chunks,
  })

  return embeddings.map((embedding, i) => ({
    content: chunks[i],
    embedding,
  }))
}

// ç”Ÿæˆå•æ¡æ–‡æœ¬çš„åµŒå…¥
async function generateEmbedding(value: string): Promise<number[]> {
  const input = value.replaceAll('\n', ' ')
  const { embedding } = await embed({
    model: 'openai/text-embedding-3-small',
    value: input,
  })
  return embedding
}
```

## ç¬¬äºŒæ­¥ï¼šå‘é‡å­˜å‚¨

å°†åµŒå…¥å‘é‡å­˜å…¥æ•°æ®åº“ã€‚è¿™é‡Œæ¼”ç¤ºä¸¤ç§æ–¹å¼ï¼šå†…å­˜å­˜å‚¨å’Œæ•°æ®åº“å­˜å‚¨ã€‚

### æ–¹å¼ä¸€ï¼šå†…å­˜å‘é‡å­˜å‚¨ï¼ˆé€‚åˆåŸå‹å¼€å‘ï¼‰

```typescript
import { cosineSimilarity, embed, embedMany } from 'ai'
import fs from 'fs'
import path from 'path'

// å†…å­˜æ•°æ®åº“
const db: { embedding: number[]; value: string }[] = []

async function buildIndex() {
  // è¯»å–æ–‡æ¡£
  const document = fs.readFileSync(
    path.join(__dirname, 'knowledge-base.txt'),
    'utf8',
  )

  // åˆ‡åˆ†å¹¶ç”ŸæˆåµŒå…¥
  const chunks = document
    .split('.')
    .map((chunk) => chunk.trim())
    .filter((chunk) => chunk.length > 0)

  const { embeddings } = await embedMany({
    model: 'openai/text-embedding-3-small',
    values: chunks,
  })

  // å­˜å…¥å†…å­˜æ•°æ®åº“
  embeddings.forEach((embedding, i) => {
    db.push({ embedding, value: chunks[i] })
  })

  console.log(`å·²ç´¢å¼• ${db.length} ä¸ªæ–‡æ¡£ç‰‡æ®µ`)
}
```

### æ–¹å¼äºŒï¼šæ•°æ®åº“å­˜å‚¨ï¼ˆç”Ÿäº§æ¨èï¼‰

ä½¿ç”¨ Drizzle ORM + PostgreSQLï¼ˆå¸¦ pgvector æ‰©å±•ï¼‰ï¼š

```typescript
import { embed, embedMany } from 'ai'
import { db } from '../db'
import { cosineDistance, desc, gt, sql } from 'drizzle-orm'
import { embeddings } from '../db/schema/embeddings'

const embeddingModel = 'openai/text-embedding-ada-002'

// æ‰¹é‡å­˜å‚¨åµŒå…¥åˆ°æ•°æ®åº“
async function storeEmbeddings(text: string) {
  const chunks = generateChunks(text)
  const { embeddings: vectors } = await embedMany({
    model: embeddingModel,
    values: chunks,
  })

  await db.insert(embeddings).values(
    vectors.map((embedding, i) => ({
      content: chunks[i],
      embedding,
    })),
  )
}
```

## ç¬¬ä¸‰æ­¥ï¼šè¯­ä¹‰æ£€ç´¢

æ ¹æ®ç”¨æˆ·æŸ¥è¯¢ï¼Œæ‰¾åˆ°æœ€ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µï¼š

### å†…å­˜ç‰ˆæ£€ç´¢

```typescript
import { cosineSimilarity, embed } from 'ai'

async function findRelevantContent(query: string, topK = 3) {
  // ç”ŸæˆæŸ¥è¯¢å‘é‡
  const { embedding: queryEmbedding } = await embed({
    model: 'openai/text-embedding-3-small',
    value: query,
  })

  // è®¡ç®—ä¸æ‰€æœ‰æ–‡æ¡£ç‰‡æ®µçš„ç›¸ä¼¼åº¦
  const results = db
    .map((item) => ({
      document: item.value,
      similarity: cosineSimilarity(queryEmbedding, item.embedding),
    }))
    .sort((a, b) => b.similarity - a.similarity)
    .slice(0, topK)

  return results.map((r) => r.document)
}
```

### æ•°æ®åº“ç‰ˆæ£€ç´¢

```typescript
import { embed } from 'ai'
import { cosineDistance, desc, gt, sql } from 'drizzle-orm'
import { embeddings } from '../db/schema/embeddings'

async function findRelevantContent(userQuery: string) {
  const { embedding: queryEmbedding } = await embed({
    model: 'openai/text-embedding-ada-002',
    value: userQuery.replaceAll('\n', ' '),
  })

  const similarity = sql<number>`1 - (${cosineDistance(
    embeddings.embedding,
    queryEmbedding,
  )})`

  const results = await db
    .select({ name: embeddings.content, similarity })
    .from(embeddings)
    .where(gt(similarity, 0.5)) // ç›¸ä¼¼åº¦é˜ˆå€¼
    .orderBy((t) => desc(t.similarity))
    .limit(4)

  return results
}
```

## ç¬¬å››æ­¥ï¼šå¢å¼ºç”Ÿæˆ

å°†æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ä¸ç”¨æˆ·é—®é¢˜ä¸€èµ·æäº¤ç»™ LLMï¼š

```typescript
import { generateText } from 'ai'

async function ragQuery(question: string) {
  // 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£
  const relevantDocs = await findRelevantContent(question)
  const context = relevantDocs.join('\n')

  // 2. ä½¿ç”¨ä¸Šä¸‹æ–‡å¢å¼ºç”Ÿæˆ
  const { text } = await generateText({
    model: 'openai/gpt-4o',
    prompt: `åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜ã€‚

ä¸Šä¸‹æ–‡ï¼š
${context}

é—®é¢˜ï¼š${question}`,
  })

  return text
}

// ä½¿ç”¨
const answer = await ragQuery('TypeScript ä¸­çš„æ³›å‹æ˜¯ä»€ä¹ˆï¼Ÿ')
console.log(answer)
```

## ç¬¬äº”æ­¥ï¼šæ„å»º RAG Agent

å°† RAG èƒ½åŠ›å°è£…ä¸ºå·¥å…·ï¼Œè®© Agent è‡ªä¸»å†³å®šä½•æ—¶æ£€ç´¢ï¼š

```typescript
import { generateText, tool, stepCountIs } from 'ai'
import { z } from 'zod'

const { text } = await generateText({
  model: 'openai/gpt-4o',
  system: `ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†åº“åŠ©æ‰‹ã€‚å½“ç”¨æˆ·æé—®æ—¶ï¼Œä½¿ç”¨ retrieve å·¥å…·æœç´¢ç›¸å…³ä¿¡æ¯ï¼Œç„¶ååŸºäºæ£€ç´¢ç»“æœå›ç­”ã€‚
å¦‚æœæ£€ç´¢ç»“æœä¸è¶³ä»¥å›ç­”é—®é¢˜ï¼Œè¯·è¯šå®åœ°å‘ŠçŸ¥ç”¨æˆ·ã€‚`,
  prompt: 'ä»€ä¹ˆæ˜¯ React Server Componentsï¼Ÿå®ƒå’Œä¼ ç»Ÿ SSR æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ',
  tools: {
    retrieve: tool({
      description: 'ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ä¸æŸ¥è¯¢ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µ',
      inputSchema: z.object({
        query: z.string().describe('æœç´¢æŸ¥è¯¢'),
      }),
      execute: async ({ query }) => {
        const results = await findRelevantContent(query)
        return results.join('\n\n')
      },
    }),
  },
  stopWhen: stepCountIs(5),
})

console.log(text)
```

## å®Œæ•´ç¤ºä¾‹

å°†ä»¥ä¸Šæ­¥éª¤æ•´åˆä¸ºä¸€ä¸ªå®Œæ•´çš„ RAG ç³»ç»Ÿï¼š

```typescript
import fs from 'fs'
import path from 'path'
import { cosineSimilarity, embed, embedMany, generateText, tool, stepCountIs } from 'ai'
import { z } from 'zod'

// ========== 1. å†…å­˜å‘é‡æ•°æ®åº“ ==========
const vectorDB: { embedding: number[]; value: string }[] = []

// ========== 2. ç´¢å¼•æ–‡æ¡£ ==========
async function indexDocument(filePath: string) {
  const content = fs.readFileSync(filePath, 'utf8')
  const chunks = content
    .split('.')
    .map((c) => c.trim())
    .filter((c) => c.length > 0)

  const { embeddings } = await embedMany({
    model: 'openai/text-embedding-3-small',
    values: chunks,
  })

  embeddings.forEach((e, i) => {
    vectorDB.push({ embedding: e, value: chunks[i] })
  })

  console.log(`å·²ç´¢å¼• ${chunks.length} ä¸ªç‰‡æ®µ`)
}

// ========== 3. è¯­ä¹‰æœç´¢ ==========
async function search(query: string, topK = 3): Promise<string[]> {
  const { embedding } = await embed({
    model: 'openai/text-embedding-3-small',
    value: query,
  })

  return vectorDB
    .map((item) => ({
      text: item.value,
      score: cosineSimilarity(embedding, item.embedding),
    }))
    .sort((a, b) => b.score - a.score)
    .slice(0, topK)
    .map((r) => r.text)
}

// ========== 4. RAG Agent ==========
async function ragAgent(question: string) {
  await indexDocument(path.join(__dirname, 'docs.txt'))

  const { text } = await generateText({
    model: 'openai/gpt-4o',
    system:
      'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯æ–‡æ¡£åŠ©æ‰‹ã€‚ä½¿ç”¨ search å·¥å…·æŸ¥æ‰¾ç›¸å…³ä¿¡æ¯åå†å›ç­”ã€‚',
    prompt: question,
    tools: {
      search: tool({
        description: 'æœç´¢çŸ¥è¯†åº“ä¸­çš„ç›¸å…³æ–‡æ¡£',
        inputSchema: z.object({ query: z.string() }),
        execute: async ({ query }) => {
          const results = await search(query)
          return results.join('\n\n')
        },
      }),
    },
    stopWhen: stepCountIs(5),
  })

  return text
}

// è¿è¡Œ
ragAgent('è§£é‡Š AI SDK ä¸­çš„ä¸­é—´ä»¶ç³»ç»Ÿ').then(console.log)
```

## ä¼˜åŒ–å»ºè®®

| ä¼˜åŒ–æ–¹å‘ | æ–¹æ³• | æ•ˆæœ |
|----------|------|------|
| åˆ‡åˆ†ç­–ç•¥ | æŒ‰æ®µè½/æ ‡é¢˜åˆ‡åˆ†ï¼Œè€ŒéæŒ‰å¥å· | ä¿æŒè¯­ä¹‰å®Œæ•´æ€§ |
| åµŒå…¥æ¨¡å‹ | ä½¿ç”¨ `text-embedding-3-large` | æ›´é«˜ç²¾åº¦ |
| é‡æ’åº | æ£€ç´¢åç”¨ LLM é‡æ’ç»“æœ | æå‡ç›¸å…³æ€§ |
| æ··åˆæ£€ç´¢ | å‘é‡æœç´¢ + å…³é”®è¯æœç´¢ | è¦†ç›–æ›´å¤šåœºæ™¯ |
| ç¼“å­˜åµŒå…¥ | ç¼“å­˜å·²è®¡ç®—çš„åµŒå…¥å‘é‡ | å‡å°‘ API è°ƒç”¨ |

## ä¸‹ä¸€æ­¥

- [å®æˆ˜ï¼šå¤šæ¨¡æ€èŠå¤©](/ai/vercel-ai-sdk/guide/tutorial-multimodal-chat) â€” æ„å»ºæ”¯æŒå›¾ç‰‡çš„èŠå¤©åº”ç”¨
- [Agent æ¦‚è§ˆ](/ai/vercel-ai-sdk/guide/agent-overview) â€” å›é¡¾ Agent åŸºç¡€æ¦‚å¿µ
- [å·¥å…·ç³»ç»Ÿ](/ai/vercel-ai-sdk/guide/tool-calling) â€” æ·±å…¥äº†è§£å·¥å…·å®šä¹‰å’Œæ‰§è¡Œ
