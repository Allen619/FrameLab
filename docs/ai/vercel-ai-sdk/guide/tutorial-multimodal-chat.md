---
title: å®æˆ˜ï¼šå¤šæ¨¡æ€èŠå¤©
description: ä»é›¶æ„å»ºä¸€ä¸ªæ”¯æŒæ–‡æœ¬å¯¹è¯å’Œå›¾ç‰‡ç”Ÿæˆçš„å¤šæ¨¡æ€èŠå¤©åº”ç”¨ï¼ŒåŸºäº Next.js å’Œ AI SDKã€‚
---

# å®æˆ˜ï¼šå¤šæ¨¡æ€èŠå¤©

æœ¬æ•™ç¨‹å°†æ„å»ºä¸€ä¸ªå¤šæ¨¡æ€èŠå¤©åº”ç”¨ï¼šç”¨æˆ·å¯ä»¥å‘é€æ–‡æœ¬æ¶ˆæ¯ï¼ŒAI ä¸ä»…èƒ½å›å¤æ–‡æœ¬ï¼Œè¿˜èƒ½æ ¹æ®éœ€è¦ç”Ÿæˆå›¾ç‰‡ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ Next.js + AI SDK + DALL-E 3 å®ç°å®Œæ•´åŠŸèƒ½ã€‚

[ğŸ”— AI SDK å¤šæ¨¡æ€èŠå¤©æœºå™¨äººæŒ‡å—](https://ai-sdk.dev/cookbook/guides/multi-modal-chatbot){target="_blank" rel="noopener"}

## é¡¹ç›®ç»“æ„

```
app/
â”œâ”€â”€ api/chat/route.ts    # åç«¯ API è·¯ç”±
â”œâ”€â”€ page.tsx             # å‰ç«¯èŠå¤©ç•Œé¢
tools/
â””â”€â”€ generate-image.ts    # å›¾ç‰‡ç”Ÿæˆå·¥å…·
```

## ç¯å¢ƒå‡†å¤‡

```bash
# åˆ›å»º Next.js é¡¹ç›®ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
npx create-next-app@latest multimodal-chat --typescript --tailwind --app

# å®‰è£…ä¾èµ–
npm install ai @ai-sdk/openai @ai-sdk/react zod
```

é…ç½®ç¯å¢ƒå˜é‡ï¼š

```bash
# .env.local
OPENAI_API_KEY=sk-your-api-key
```

## ç¬¬ä¸€æ­¥ï¼šå®šä¹‰å›¾ç‰‡ç”Ÿæˆå·¥å…·

åˆ›å»ºä¸€ä¸ª AI SDK å·¥å…·ï¼Œå°è£… DALL-E 3 å›¾ç‰‡ç”Ÿæˆèƒ½åŠ›ï¼š

```typescript
// tools/generate-image.ts
import { generateImage, tool } from 'ai'
import { openai } from '@ai-sdk/openai'
import { z } from 'zod'

export const generateImageTool = tool({
  description: 'æ ¹æ®æ–‡æœ¬æè¿°ç”Ÿæˆå›¾ç‰‡',
  inputSchema: z.object({
    prompt: z.string().describe('å›¾ç‰‡æè¿°ï¼Œç”¨è‹±æ–‡ç¼–å†™æ•ˆæœæ›´å¥½'),
  }),
  execute: async ({ prompt }) => {
    const { image } = await generateImage({
      model: openai.image('dall-e-3'),
      prompt,
    })

    // ç”Ÿäº§ç¯å¢ƒå»ºè®®ï¼šå°†å›¾ç‰‡ä¿å­˜åˆ° Blob å­˜å‚¨ï¼Œè¿”å› URL
    // è¿™é‡Œä¸ºç®€åŒ–æ¼”ç¤ºï¼Œç›´æ¥è¿”å› base64
    return { image: image.base64, prompt }
  },
})
```

## ç¬¬äºŒæ­¥ï¼šåˆ›å»º API è·¯ç”±

```typescript
// app/api/chat/route.ts
import {
  convertToModelMessages,
  type InferUITools,
  stepCountIs,
  streamText,
  type UIMessage,
} from 'ai'
import { generateImageTool } from '@/tools/generate-image'

// æ³¨å†Œå·¥å…·
const tools = {
  generateImage: generateImageTool,
}

// å¯¼å‡ºå·¥å…·ç±»å‹ï¼Œä¾›å‰ç«¯ä½¿ç”¨
export type ChatTools = InferUITools<typeof tools>

export async function POST(request: Request) {
  const { messages }: { messages: UIMessage[] } = await request.json()

  const result = streamText({
    model: 'openai/gpt-4o',
    system: `ä½ æ˜¯ä¸€ä¸ªå¤šæ¨¡æ€åŠ©æ‰‹ã€‚ä½ å¯ä»¥å›ç­”æ–‡æœ¬é—®é¢˜ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ generateImage å·¥å…·ç”Ÿæˆå›¾ç‰‡ã€‚
å½“ç”¨æˆ·è¯·æ±‚ç”Ÿæˆå›¾ç‰‡æ—¶ï¼Œå…ˆå°†æè¿°ç¿»è¯‘ä¸ºè¯¦ç»†çš„è‹±æ–‡ promptï¼Œå†è°ƒç”¨å·¥å…·ã€‚
ç”Ÿæˆå›¾ç‰‡åï¼Œç”¨ä¸­æ–‡ç®€è¦æè¿°ä½ ç”Ÿæˆäº†ä»€ä¹ˆã€‚`,
    messages: await convertToModelMessages(messages),
    stopWhen: stepCountIs(5),
    tools,
  })

  return result.toUIMessageStreamResponse()
}
```

## ç¬¬ä¸‰æ­¥ï¼šæ„å»ºèŠå¤©ç•Œé¢

```typescript
// app/page.tsx
'use client'

import { useChat } from '@ai-sdk/react'
import { DefaultChatTransport, type UIMessage } from 'ai'
import Image from 'next/image'
import { type FormEvent, useState } from 'react'
import type { ChatTools } from './api/chat/route'

type ChatMessage = UIMessage<never, never, ChatTools>

export default function Chat() {
  const [input, setInput] = useState('')

  const { messages, sendMessage } = useChat<ChatMessage>({
    transport: new DefaultChatTransport({
      api: '/api/chat',
    }),
  })

  const handleInputChange = (event: React.ChangeEvent<HTMLInputElement>) => {
    setInput(event.target.value)
  }

  const handleSubmit = async (event: FormEvent<HTMLFormElement>) => {
    event.preventDefault()

    sendMessage({
      parts: [{ type: 'text', text: input }],
    })

    setInput('')
  }

  return (
    <div className="flex flex-col w-full max-w-md py-24 mx-auto stretch">
      <h1 className="text-2xl font-bold mb-4">å¤šæ¨¡æ€èŠå¤©</h1>

      <div className="space-y-4 mb-4">
        {messages.map((message) => (
          <div key={message.id} className="whitespace-pre-wrap">
            <div className="font-bold">
              {message.role === 'user' ? 'ä½ ' : 'AI'}
            </div>

            {message.parts.map((part, partIndex) => {
              const { type } = part

              // æ¸²æŸ“æ–‡æœ¬å†…å®¹
              if (type === 'text') {
                return (
                  <div key={`${message.id}-part-${partIndex}`}>
                    {part.text}
                  </div>
                )
              }

              // æ¸²æŸ“å›¾ç‰‡ç”Ÿæˆå·¥å…·çš„ç»“æœ
              if (type === 'tool-generateImage') {
                const { state, toolCallId } = part

                // å·¥å…·æ­£åœ¨æ‰§è¡Œ
                if (state === 'input-available') {
                  return (
                    <div
                      key={`${message.id}-part-${partIndex}`}
                      className="text-gray-500 italic"
                    >
                      æ­£åœ¨ç”Ÿæˆå›¾ç‰‡...
                    </div>
                  )
                }

                // å·¥å…·æ‰§è¡Œå®Œæˆï¼Œæ˜¾ç¤ºç”Ÿæˆçš„å›¾ç‰‡
                if (state === 'output-available') {
                  const { input: toolInput, output } = part

                  return (
                    <div key={toolCallId} className="mt-2">
                      <Image
                        src={`data:image/png;base64,${output.image}`}
                        alt={toolInput.prompt}
                        height={400}
                        width={400}
                        className="rounded-lg shadow-md"
                      />
                      <p className="text-sm text-gray-500 mt-1">
                        Prompt: {toolInput.prompt}
                      </p>
                    </div>
                  )
                }
              }

              return null
            })}
          </div>
        ))}
      </div>

      <form onSubmit={handleSubmit} className="fixed bottom-0 w-full max-w-md">
        <input
          className="w-full p-2 mb-8 border border-gray-300 rounded shadow-xl"
          value={input}
          placeholder="è¾“å…¥æ¶ˆæ¯ï¼Œæˆ–è¦æ±‚ç”Ÿæˆå›¾ç‰‡..."
          onChange={handleInputChange}
        />
      </form>
    </div>
  )
}
```

## ç¬¬å››æ­¥ï¼šå¤„ç†å›¾ç‰‡ä¸Šä¼ ï¼ˆå¯é€‰ï¼‰

å¦‚æœéœ€è¦ç”¨æˆ·ä¸Šä¼ å›¾ç‰‡è¿›è¡Œåˆ†æï¼Œå¯ä»¥æ‰©å±•æ¶ˆæ¯æ ¼å¼ï¼š

```typescript
// app/page.tsxï¼ˆæ‰©å±•ç‰ˆï¼‰
'use client'

import { useChat } from '@ai-sdk/react'
import { DefaultChatTransport } from 'ai'
import { type FormEvent, useRef, useState } from 'react'

export default function Chat() {
  const [input, setInput] = useState('')
  const fileInputRef = useRef<HTMLInputElement>(null)

  const { messages, sendMessage } = useChat({
    transport: new DefaultChatTransport({
      api: '/api/chat',
    }),
  })

  const handleSubmit = async (event: FormEvent<HTMLFormElement>) => {
    event.preventDefault()

    const files = fileInputRef.current?.files
    const parts: any[] = [{ type: 'text', text: input }]

    // å¦‚æœæœ‰ä¸Šä¼ çš„å›¾ç‰‡ï¼Œæ·»åŠ åˆ°æ¶ˆæ¯ä¸­
    if (files && files.length > 0) {
      for (const file of Array.from(files)) {
        const base64 = await fileToBase64(file)
        parts.push({
          type: 'image',
          image: base64,
          mimeType: file.type,
        })
      }
    }

    sendMessage({ parts })
    setInput('')

    // æ¸…ç©ºæ–‡ä»¶è¾“å…¥
    if (fileInputRef.current) {
      fileInputRef.current.value = ''
    }
  }

  return (
    <div className="flex flex-col w-full max-w-md py-24 mx-auto">
      {/* æ¶ˆæ¯åˆ—è¡¨... */}

      <form onSubmit={handleSubmit} className="flex gap-2">
        <input
          type="file"
          accept="image/*"
          ref={fileInputRef}
          className="hidden"
        />
        <button
          type="button"
          onClick={() => fileInputRef.current?.click()}
          className="px-3 py-2 border rounded"
        >
          ğŸ“
        </button>
        <input
          className="flex-1 p-2 border rounded"
          value={input}
          placeholder="è¾“å…¥æ¶ˆæ¯..."
          onChange={(e) => setInput(e.target.value)}
        />
        <button type="submit" className="px-4 py-2 bg-blue-500 text-white rounded">
          å‘é€
        </button>
      </form>
    </div>
  )
}

// å·¥å…·å‡½æ•°ï¼šæ–‡ä»¶è½¬ base64
function fileToBase64(file: File): Promise<string> {
  return new Promise((resolve, reject) => {
    const reader = new FileReader()
    reader.onload = () => {
      const result = reader.result as string
      resolve(result.split(',')[1]) // å»æ‰ data:image/xxx;base64, å‰ç¼€
    }
    reader.onerror = reject
    reader.readAsDataURL(file)
  })
}
```

å¯¹åº”çš„åç«¯è·¯ç”±å·²ç»é€šè¿‡ `convertToModelMessages` è‡ªåŠ¨å¤„ç†å›¾ç‰‡æ¶ˆæ¯ï¼Œæ— éœ€é¢å¤–ä¿®æ”¹ã€‚

## ä½¿ç”¨ Google Gemini ç”Ÿæˆå›¾ç‰‡

é™¤äº† DALL-E 3ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ Google Gemini çš„å›¾ç‰‡ç”Ÿæˆèƒ½åŠ›ï¼š

```typescript
// tools/generate-image-gemini.ts
import { generateImage, tool } from 'ai'
import { google } from '@ai-sdk/google'
import { z } from 'zod'

export const generateImageToolGemini = tool({
  description: 'ä½¿ç”¨ Gemini ç”Ÿæˆå›¾ç‰‡',
  inputSchema: z.object({
    prompt: z.string().describe('å›¾ç‰‡æè¿°'),
    aspectRatio: z
      .enum(['1:1', '16:9', '9:16', '4:3', '3:4'])
      .default('1:1')
      .describe('å›¾ç‰‡å®½é«˜æ¯”'),
  }),
  execute: async ({ prompt, aspectRatio }) => {
    const { image } = await generateImage({
      model: google.image('gemini-2.5-flash-image'),
      prompt,
      aspectRatio,
    })
    return { image: image.base64, prompt }
  },
})
```

## è¿è¡Œé¡¹ç›®

```bash
npm run dev
```

è®¿é—® `http://localhost:3000`ï¼Œä½ å¯ä»¥ï¼š

1. è¾“å…¥æ–‡æœ¬é—®é¢˜ï¼ŒAI å›å¤æ–‡æœ¬
2. è¾“å…¥ "å¸®æˆ‘ç”»ä¸€åªæˆ´ç€å·«å¸ˆå¸½çš„çŒ«"ï¼ŒAI è‡ªåŠ¨è°ƒç”¨å›¾ç‰‡ç”Ÿæˆå·¥å…·
3. ä¸Šä¼ å›¾ç‰‡ï¼ŒAI åˆ†æå›¾ç‰‡å†…å®¹ï¼ˆGPT-4o æ”¯æŒå¤šæ¨¡æ€è¾“å…¥ï¼‰

## ç”Ÿäº§ç¯å¢ƒä¼˜åŒ–

| ä¼˜åŒ–ç‚¹ | è¯´æ˜ |
|--------|------|
| å›¾ç‰‡å­˜å‚¨ | å°† base64 å›¾ç‰‡ä¿å­˜åˆ° Blob å­˜å‚¨ï¼ˆå¦‚ Vercel Blobï¼‰ï¼Œè¿”å› URL |
| å›¾ç‰‡å‹ç¼© | ä¸Šä¼ çš„å›¾ç‰‡è¿›è¡Œå‹ç¼©ï¼Œå‡å°‘ Token æ¶ˆè€— |
| å¹¶å‘é™åˆ¶ | é™åˆ¶å›¾ç‰‡ç”Ÿæˆçš„å¹¶å‘æ•°ï¼Œé¿å… API é…é¢è€—å°½ |
| ç¼“å­˜ç­–ç•¥ | å¯¹ç›¸åŒ prompt çš„å›¾ç‰‡ç”Ÿæˆç»“æœè¿›è¡Œç¼“å­˜ |
| æµå¼è¿›åº¦ | å›¾ç‰‡ç”Ÿæˆè¿‡ç¨‹ä¸­å±•ç¤ºè¿›åº¦æç¤º |

## ä¸‹ä¸€æ­¥

- [å®æˆ˜ï¼šRAG Agent](/ai/vercel-ai-sdk/guide/tutorial-rag-agent) â€” æ„å»ºåŸºäºçŸ¥è¯†åº“çš„æ™ºèƒ½é—®ç­”
- [æ„å»º Agent](/ai/vercel-ai-sdk/guide/building-agents) â€” å­¦ä¹  Agent çš„å·¥å…·å¾ªç¯æœºåˆ¶
- [Provider é€‰å‹æŒ‡å—](/ai/vercel-ai-sdk/guide/providers) â€” äº†è§£ä¸åŒ Provider çš„å¤šæ¨¡æ€èƒ½åŠ›
