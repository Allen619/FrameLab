---
title: RAG åŸºç¡€æ¦‚å¿µ
description: ç†è§£æ£€ç´¢å¢å¼ºç”Ÿæˆçš„æ ¸å¿ƒåŸç†å’Œå·¥ä½œæµç¨‹ï¼Œæ„å»ºä½ çš„ç¬¬ä¸€ä¸ª RAG åº”ç”¨
---

# RAG åŸºç¡€æ¦‚å¿µ

## æ¦‚è¿°

æœ¬ç« å°†å¸®åŠ©ä½ ç†è§£ **RAGï¼ˆRetrieval-Augmented Generationï¼Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰** çš„æ ¸å¿ƒåŸç†ã€‚å®Œæˆæœ¬ç« åï¼Œä½ å°†èƒ½å¤Ÿï¼š

- ç”¨é€šä¿—è¯­è¨€è§£é‡Š RAG æ˜¯ä»€ä¹ˆ
- ç†è§£ RAG çš„å·¥ä½œæµç¨‹
- æ„å»ºä¸€ä¸ªèƒ½å¯¹æœ¬åœ°æ–‡æ¡£è¿›è¡Œé—®ç­”çš„ RAG åº”ç”¨
- æŒæ¡ LlamaIndex çš„æ ¸å¿ƒç»„ä»¶

## æ ¸å¿ƒæ¦‚å¿µ

### ä»€ä¹ˆæ˜¯ RAGï¼Ÿ

**RAG** å°±åƒ**è€ƒè¯•å‰æŸ¥é˜…ç¬”è®°å†ç­”é¢˜**ã€‚

æƒ³è±¡ä½ åœ¨å‚åŠ ä¸€åœºå¼€å·è€ƒè¯•ï¼š

1. **ä¼ ç»Ÿ LLM**ï¼ˆé—­å·ï¼‰ï¼šåªèƒ½ä¾é å¤§è„‘é‡Œè®°ä½çš„çŸ¥è¯†å›ç­”é—®é¢˜
2. **RAG**ï¼ˆå¼€å·ï¼‰ï¼šå¯ä»¥å…ˆæŸ¥é˜…ç¬”è®°ï¼Œæ‰¾åˆ°ç›¸å…³å†…å®¹ï¼Œå†ç»“åˆç†è§£å›ç­”é—®é¢˜

```mermaid
graph TD
    A[ç”¨æˆ·æé—®] --> B{é€‰æ‹©æ¨¡å¼}
    B -->|ä¼ ç»Ÿ LLM| C[ä»…ä¾é æ¨¡å‹è®°å¿†]
    B -->|RAG| D[æ£€ç´¢ç›¸å…³æ–‡æ¡£]
    D --> E[è·å–ä¸Šä¸‹æ–‡]
    E --> F[ç»“åˆä¸Šä¸‹æ–‡ç”Ÿæˆç­”æ¡ˆ]
    C --> G[å¯èƒ½äº§ç”Ÿå¹»è§‰]
    F --> H[å‡†ç¡®ä¸”æœ‰æ®å¯æŸ¥]
```

**å›¾è¡¨è¯´æ˜**: RAG é€šè¿‡æ£€ç´¢å¤–éƒ¨çŸ¥è¯†å¢å¼º LLM çš„å›ç­”èƒ½åŠ›ï¼Œå‡å°‘"å¹»è§‰"ï¼ˆç¼–é€ ä¿¡æ¯ï¼‰çš„å‘ç”Ÿã€‚

### ä¸ºä»€ä¹ˆéœ€è¦ RAGï¼Ÿ

| é—®é¢˜ | ä¼ ç»Ÿ LLM | RAG |
|------|----------|-----|
| çŸ¥è¯†è¿‡æ—¶ | åªçŸ¥é“è®­ç»ƒæˆªæ­¢æ—¥æœŸå‰çš„ä¿¡æ¯ | å¯ä»¥æ£€ç´¢æœ€æ–°æ–‡æ¡£ |
| ç§æœ‰æ•°æ® | æ— æ³•è®¿é—®ä¼ä¸šå†…éƒ¨æ–‡æ¡£ | å¯ä»¥ç´¢å¼•ä»»æ„ç§æœ‰æ•°æ® |
| å‡†ç¡®æ€§ | å¯èƒ½"ç¼–é€ "ç­”æ¡ˆ | ç­”æ¡ˆæœ‰æ®å¯æŸ¥ |
| å¯è§£é‡Šæ€§ | æ— æ³•è¿½æº¯ä¿¡æ¯æ¥æº | å¯ä»¥å¼•ç”¨åŸå§‹æ–‡æ¡£ |

### RAG çš„å·¥ä½œæµç¨‹

RAG çš„æ ¸å¿ƒæµç¨‹å¯ä»¥åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼š

```mermaid
graph TD
    subgraph ç´¢å¼•é˜¶æ®µ
        A1[åŸå§‹æ–‡æ¡£] --> A2[åˆ‡åˆ†æˆå°å— Chunks]
        A2 --> A3[ç”Ÿæˆ Embedding å‘é‡]
        A3 --> A4[å­˜å…¥å‘é‡æ•°æ®åº“]
    end

    subgraph æŸ¥è¯¢é˜¶æ®µ
        B1[ç”¨æˆ·é—®é¢˜] --> B2[ç”Ÿæˆé—®é¢˜ Embedding]
        B2 --> B3[å‘é‡ç›¸ä¼¼åº¦æœç´¢]
        B3 --> B4[è·å–ç›¸å…³ Chunks]
        B4 --> B5[æ„å»º Prompt]
        B5 --> B6[LLM ç”Ÿæˆç­”æ¡ˆ]
    end

    A4 -.-> B3
```

**å›¾è¡¨è¯´æ˜**:
- **ç´¢å¼•é˜¶æ®µ**ï¼šå°†æ–‡æ¡£åˆ‡åˆ†ã€å‘é‡åŒ–å¹¶å­˜å‚¨ï¼Œç±»ä¼¼å›¾ä¹¦é¦†å»ºç«‹ç´¢å¼•å¡ç‰‡
- **æŸ¥è¯¢é˜¶æ®µ**ï¼šå°†é—®é¢˜å‘é‡åŒ–ï¼Œæ£€ç´¢ç›¸å…³å†…å®¹ï¼Œè®© LLM ç”Ÿæˆç­”æ¡ˆ

## LlamaIndex æ ¸å¿ƒç»„ä»¶

[ğŸ”— LlamaIndex RAG æ¦‚å¿µä¸æµç¨‹](https://docs.llamaindex.ai/en/stable/understanding/){target="_blank" rel="noopener"}

### ç»„ä»¶æ¦‚è§ˆ

LlamaIndex å°† RAG æµç¨‹å°è£…æˆå‡ ä¸ªæ ¸å¿ƒç»„ä»¶ï¼š

| ç»„ä»¶ | ç±»æ¯” | ä½œç”¨ |
|------|------|------|
| **Document** | ä¸€æœ¬ä¹¦ | åŸå§‹æ•°æ®çš„å®¹å™¨ |
| **Node** | ä¹¦ä¸­çš„æ®µè½ | åˆ‡åˆ†åçš„æ–‡æœ¬å— |
| **Index** | ä¹¦çš„ç›®å½• | é«˜æ•ˆæ£€ç´¢çš„æ•°æ®ç»“æ„ |
| **Query Engine** | é—®ç­”åŠ©æ‰‹ | å¤„ç†ç”¨æˆ·æŸ¥è¯¢å¹¶è¿”å›ç­”æ¡ˆ |
| **Retriever** | å›¾ä¹¦ç®¡ç†å‘˜ | è´Ÿè´£æ‰¾åˆ°ç›¸å…³å†…å®¹ |

### ç»„ä»¶å…³ç³»å›¾

```mermaid
graph TD
    A[Documents æ–‡æ¡£] --> B[Nodes èŠ‚ç‚¹]
    B --> C[Index ç´¢å¼•]
    C --> D[Retriever æ£€ç´¢å™¨]
    D --> E[Query Engine æŸ¥è¯¢å¼•æ“]
    E --> F[Response å“åº”]

    G[ç”¨æˆ·é—®é¢˜] --> E
```

**å›¾è¡¨è¯´æ˜**: æ•°æ®ä» Document æµå‘ Nodeï¼Œå»ºç«‹ Index åï¼ŒQuery Engine é€šè¿‡ Retriever æ£€ç´¢ç›¸å…³å†…å®¹å¹¶ç”Ÿæˆå“åº”ã€‚

## ä»£ç ç¤ºä¾‹

### ç¤ºä¾‹ 1: æœ€å° RAG åº”ç”¨

> é€‚ç”¨ç‰ˆæœ¬: LlamaIndex 0.10.x+

[ğŸ”— VectorStoreIndex API å‚è€ƒ](https://docs.llamaindex.ai/en/stable/module_guides/indexing/vector_store_index/){target="_blank" rel="noopener"}

```python
# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader

# æ­¥éª¤ 1: åŠ è½½æ–‡æ¡£
# SimpleDirectoryReader ä¼šè¯»å–æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
documents = SimpleDirectoryReader("./data/").load_data()

# æ­¥éª¤ 2: åˆ›å»ºç´¢å¼•
# VectorStoreIndex ä¼šè‡ªåŠ¨ï¼š
# - å°†æ–‡æ¡£åˆ‡åˆ†æˆ Nodes
# - ä¸ºæ¯ä¸ª Node ç”Ÿæˆ Embedding
# - å»ºç«‹å‘é‡ç´¢å¼•
index = VectorStoreIndex.from_documents(documents)

# æ­¥éª¤ 3: åˆ›å»ºæŸ¥è¯¢å¼•æ“
query_engine = index.as_query_engine()

# æ­¥éª¤ 4: æ‰§è¡ŒæŸ¥è¯¢
response = query_engine.query("è¿™ä»½æ–‡æ¡£çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ")
print(response)
```

**è¯´æ˜**: è¿™æ˜¯æœ€ç®€æ´çš„ RAG å®ç°ï¼Œä»…éœ€ 4 è¡Œæ ¸å¿ƒä»£ç ã€‚LlamaIndex åœ¨åº•å±‚å®Œæˆäº†æ‰€æœ‰å¤æ‚çš„å¤„ç†ã€‚

### ç¤ºä¾‹ 2: å¯¹ PDF æ–‡ä»¶è¿›è¡Œé—®ç­”

> é€‚ç”¨ç‰ˆæœ¬: LlamaIndex 0.10.x+

```python
# å®‰è£… PDF è§£æä¾èµ–
# pip install pypdf

from llama_index.core import VectorStoreIndex, SimpleDirectoryReader

# åŠ è½½ PDF æ–‡ä»¶
# å°†ä½ çš„ PDF æ”¾å…¥ ./pdf_docs/ ç›®å½•
documents = SimpleDirectoryReader(
    input_dir="./pdf_docs/",
    required_exts=[".pdf"],  # åªè¯»å– PDF æ–‡ä»¶
).load_data()

print(f"åŠ è½½äº† {len(documents)} ä¸ªæ–‡æ¡£")

# åˆ›å»ºç´¢å¼•
index = VectorStoreIndex.from_documents(documents)

# åˆ›å»ºæŸ¥è¯¢å¼•æ“
query_engine = index.as_query_engine()

# äº¤äº’å¼é—®ç­”
while True:
    question = input("\nè¯·è¾“å…¥é—®é¢˜ï¼ˆè¾“å…¥ 'quit' é€€å‡ºï¼‰: ")
    if question.lower() == 'quit':
        break

    response = query_engine.query(question)
    print(f"\nå›ç­”: {response}")
```

**è¯´æ˜**: è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•å¯¹ PDF æ–‡æ¡£è¿›è¡Œé—®ç­”ï¼Œæ˜¯æœ€å¸¸è§çš„ RAG åº”ç”¨åœºæ™¯ã€‚

### ç¤ºä¾‹ 3: ä½¿ç”¨æœ¬åœ°æ¨¡å‹

> é€‚ç”¨ç‰ˆæœ¬: LlamaIndex 0.10.x+

```python
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings
from llama_index.llms.ollama import Ollama
from llama_index.embeddings.ollama import OllamaEmbedding

# é…ç½®ä½¿ç”¨ Ollama æœ¬åœ°æ¨¡å‹
Settings.llm = Ollama(model="llama3.2", request_timeout=120.0)
Settings.embed_model = OllamaEmbedding(model_name="nomic-embed-text")

# åŠ è½½æ–‡æ¡£
documents = SimpleDirectoryReader("./data/").load_data()

# åˆ›å»ºç´¢å¼•
index = VectorStoreIndex.from_documents(documents)

# æŸ¥è¯¢
query_engine = index.as_query_engine()
response = query_engine.query("æ–‡æ¡£çš„æ ¸å¿ƒè§‚ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ")
print(response)
```

**è¯´æ˜**: ä½¿ç”¨ Ollama å¯ä»¥å®Œå…¨åœ¨æœ¬åœ°è¿è¡Œ RAG åº”ç”¨ï¼Œæ— éœ€ç½‘ç»œè¿æ¥å’Œ API è´¹ç”¨ã€‚

## æ·±å…¥ç†è§£ Embedding

### ä»€ä¹ˆæ˜¯ Embeddingï¼Ÿ

**Embedding** å°±åƒ**å°†æ–‡å­—è½¬åŒ–ä¸ºè®¡ç®—æœºèƒ½ç†è§£çš„åæ ‡ä½ç½®**ã€‚

æƒ³è±¡ä¸€ä¸ªåŸå¸‚åœ°å›¾ï¼š
- "å’–å•¡é¦†"å’Œ"æ˜Ÿå·´å…‹"åœ¨åœ°å›¾ä¸Šè·ç¦»å¾ˆè¿‘ï¼ˆè¯­ä¹‰ç›¸ä¼¼ï¼‰
- "å’–å•¡é¦†"å’Œ"æ±½è½¦"åœ¨åœ°å›¾ä¸Šè·ç¦»å¾ˆè¿œï¼ˆè¯­ä¹‰ä¸åŒï¼‰

```mermaid
graph TD
    A[æ–‡æœ¬: å’–å•¡é¦†] --> B[Embedding æ¨¡å‹]
    B --> C["å‘é‡: [0.23, 0.87, ...]"]

    D[æ–‡æœ¬: æ˜Ÿå·´å…‹] --> E[Embedding æ¨¡å‹]
    E --> F["å‘é‡: [0.25, 0.85, ...]"]

    G[ç›¸ä¼¼åº¦è®¡ç®—] --> H[è·ç¦»å¾ˆè¿‘ = è¯­ä¹‰ç›¸ä¼¼]
    C --> G
    F --> G
```

**å›¾è¡¨è¯´æ˜**: Embedding å°†æ–‡æœ¬è½¬æ¢ä¸ºé«˜ç»´å‘é‡ï¼Œè¯­ä¹‰ç›¸ä¼¼çš„æ–‡æœ¬åœ¨å‘é‡ç©ºé—´ä¸­è·ç¦»æ›´è¿‘ã€‚

### å‘é‡ç›¸ä¼¼åº¦æœç´¢

å½“ç”¨æˆ·æé—®æ—¶ï¼š
1. å°†é—®é¢˜è½¬æ¢ä¸º Embedding å‘é‡
2. åœ¨ç´¢å¼•ä¸­æ‰¾åˆ°è·ç¦»æœ€è¿‘çš„å‡ ä¸ªæ–‡æ¡£å—
3. å°†è¿™äº›å—ä½œä¸ºä¸Šä¸‹æ–‡å‘é€ç»™ LLM

## é¿å‘æŒ‡å—

### âŒ å¸¸è§é—®é¢˜ 1: å›ç­”"æˆ‘ä¸çŸ¥é“"

**ç°è±¡**:

```
LLM å›ç­”: "æ ¹æ®æä¾›çš„ä¸Šä¸‹æ–‡ï¼Œæˆ‘æ— æ³•æ‰¾åˆ°ç›¸å…³ä¿¡æ¯..."
```

**æ ¹å› **: æ–‡æ¡£æ²¡æœ‰æ­£ç¡®åŠ è½½ï¼Œæˆ–æ£€ç´¢æ²¡æœ‰æ‰¾åˆ°ç›¸å…³å†…å®¹ã€‚

**è§£å†³æ–¹æ¡ˆ**:

```python
# æ£€æŸ¥æ–‡æ¡£æ˜¯å¦æ­£ç¡®åŠ è½½
documents = SimpleDirectoryReader("./data/").load_data()
print(f"åŠ è½½äº† {len(documents)} ä¸ªæ–‡æ¡£")

# æ£€æŸ¥ç¬¬ä¸€ä¸ªæ–‡æ¡£çš„å†…å®¹
if documents:
    print(f"ç¬¬ä¸€ä¸ªæ–‡æ¡£é¢„è§ˆ: {documents[0].text[:200]}")
```

**é¢„é˜²æªæ–½**: å§‹ç»ˆéªŒè¯æ–‡æ¡£åŠ è½½ç»“æœï¼Œç¡®ä¿æ•°æ®æ­£ç¡®å¯¼å…¥ã€‚

### âŒ å¸¸è§é—®é¢˜ 2: å›ç­”ä¸é—®é¢˜æ— å…³

**ç°è±¡**: LLM çš„å›ç­”è™½ç„¶çœ‹èµ·æ¥åˆç†ï¼Œä½†ä¸ç”¨æˆ·çš„å®é™…é—®é¢˜ä¸ç›¸å…³ã€‚

**æ ¹å› **: æ£€ç´¢çš„ top_k è®¾ç½®è¿‡å°ï¼Œæˆ– chunk_size ä¸åˆç†ã€‚

**è§£å†³æ–¹æ¡ˆ**:

```python
# å¢åŠ æ£€ç´¢æ•°é‡
query_engine = index.as_query_engine(
    similarity_top_k=5  # é»˜è®¤æ˜¯ 2ï¼Œå¢åŠ åˆ° 5
)

# æˆ–åœ¨åˆ›å»ºç´¢å¼•æ—¶è°ƒæ•´ chunk å¤§å°
from llama_index.core.node_parser import SentenceSplitter

# ä½¿ç”¨æ›´å¤§çš„ chunk
splitter = SentenceSplitter(chunk_size=1024, chunk_overlap=200)
```

**é¢„é˜²æªæ–½**: æ ¹æ®æ–‡æ¡£ç‰¹ç‚¹è°ƒæ•´ chunk_size å’Œ top_kã€‚

### âŒ å¸¸è§é—®é¢˜ 3: ä¸­æ–‡å¤„ç†æ•ˆæœå·®

**ç°è±¡**: å¯¹ä¸­æ–‡æ–‡æ¡£çš„é—®ç­”æ•ˆæœæ˜æ˜¾ä¸å¦‚è‹±æ–‡ã€‚

**æ ¹å› **: é»˜è®¤çš„ Embedding æ¨¡å‹å¯¹ä¸­æ–‡æ”¯æŒæœ‰é™ã€‚

**è§£å†³æ–¹æ¡ˆ**:

```python
# ä½¿ç”¨æ”¯æŒä¸­æ–‡çš„ Embedding æ¨¡å‹
from llama_index.embeddings.huggingface import HuggingFaceEmbedding

Settings.embed_model = HuggingFaceEmbedding(
    model_name="BAAI/bge-small-zh-v1.5"
)
```

**é¢„é˜²æªæ–½**: ä¸­æ–‡åœºæ™¯ä¼˜å…ˆé€‰æ‹©ä¸“é—¨ä¼˜åŒ–çš„ä¸­æ–‡ Embedding æ¨¡å‹ã€‚

### âŒ å¸¸è§é—®é¢˜ 4: å†…å­˜ä¸è¶³

**ç°è±¡**:

```
MemoryError: Unable to allocate array
```

**æ ¹å› **: ä¸€æ¬¡æ€§åŠ è½½è¿‡å¤šæ–‡æ¡£ã€‚

**è§£å†³æ–¹æ¡ˆ**:

```python
# åˆ†æ‰¹å¤„ç†å¤§é‡æ–‡æ¡£
from llama_index.core import StorageContext

# åˆ›å»ºå¯æŒä¹…åŒ–çš„ç´¢å¼•
storage_context = StorageContext.from_defaults()
index = VectorStoreIndex.from_documents(
    documents[:100],  # å…ˆå¤„ç†å‰ 100 ä¸ª
    storage_context=storage_context,
)

# æŒä¹…åŒ–ä¿å­˜
index.storage_context.persist(persist_dir="./storage")
```

**é¢„é˜²æªæ–½**: å¤§è§„æ¨¡æ–‡æ¡£å¤„ç†æ—¶ä½¿ç”¨æŒä¹…åŒ–å­˜å‚¨å’Œåˆ†æ‰¹å¤„ç†ã€‚

## ç”Ÿäº§æœ€ä½³å®è·µ

### å‚æ•°æ¨è

| å‚æ•° | æ¨èå€¼ | è¯´æ˜ |
|------|--------|------|
| chunk_size | 512-1024 | å¹³è¡¡æ£€ç´¢ç²¾åº¦å’Œä¸Šä¸‹æ–‡é•¿åº¦ |
| chunk_overlap | 50-200 | é¿å…é‡è¦ä¿¡æ¯è¢«åˆ‡æ–­ |
| similarity_top_k | 3-5 | é¿å…è¿‡å¤šä¸ç›¸å…³ç»“æœå¹²æ‰° |

### ç´¢å¼•æŒä¹…åŒ–

```python
# ä¿å­˜ç´¢å¼•ï¼Œé¿å…æ¯æ¬¡é‡æ–°æ„å»º
index.storage_context.persist(persist_dir="./storage")

# åŠ è½½å·²ä¿å­˜çš„ç´¢å¼•
from llama_index.core import StorageContext, load_index_from_storage

storage_context = StorageContext.from_defaults(persist_dir="./storage")
index = load_index_from_storage(storage_context)
```

### æ€§èƒ½ä¼˜åŒ–

```python
# ä½¿ç”¨æµå¼å“åº”ï¼Œæå‡ç”¨æˆ·ä½“éªŒ
query_engine = index.as_query_engine(streaming=True)

streaming_response = query_engine.query("ä½ çš„é—®é¢˜")
for text in streaming_response.response_gen:
    print(text, end="", flush=True)
```

## å°ç»“

æœ¬ç« æˆ‘ä»¬å­¦ä¹ äº†ï¼š

1. âœ… **RAG æ¦‚å¿µ**ï¼šè€ƒè¯•å‰æŸ¥ç¬”è®°å†ç­”é¢˜çš„æ™ºèƒ½é—®ç­”æ¨¡å¼
2. âœ… **æ ¸å¿ƒç»„ä»¶**ï¼šDocumentã€Nodeã€Indexã€Query Engine
3. âœ… **Embedding**ï¼šå°†æ–‡å­—è½¬åŒ–ä¸ºè®¡ç®—æœºèƒ½ç†è§£çš„åæ ‡
4. âœ… **å®æˆ˜åº”ç”¨**ï¼šå¯¹æœ¬åœ° PDF è¿›è¡Œé—®ç­”

### RAG æ ¸å¿ƒè¦ç‚¹å›é¡¾

```mermaid
graph TD
    A[æ–‡æ¡£] -->|åˆ‡åˆ†| B[Chunks]
    B -->|å‘é‡åŒ–| C[Embeddings]
    C -->|å­˜å‚¨| D[Vector Index]
    E[é—®é¢˜] -->|å‘é‡åŒ–| F[Query Embedding]
    F -->|ç›¸ä¼¼åº¦æœç´¢| D
    D -->|Top-K| G[ç›¸å…³ä¸Šä¸‹æ–‡]
    G -->|Prompt| H[LLM]
    H --> I[ç­”æ¡ˆ]
```

## ä¸‹ä¸€æ­¥

ç°åœ¨ä½ å·²ç»ç†è§£äº† RAG çš„æ ¸å¿ƒåŸç†ï¼Œæ¥ä¸‹æ¥è®©æˆ‘ä»¬å­¦ä¹ ï¼š

- [æ•°æ®åŠ è½½](/ai/llamaindex/guide/data-connectors) - æŒæ¡å¤šç§æ•°æ®æºçš„åŠ è½½æ–¹æ³•
- [ç´¢å¼•æ„å»º](/ai/llamaindex/guide/index-building) - æ·±å…¥ç†è§£ç´¢å¼•ç±»å‹å’ŒæŒä¹…åŒ–ç­–ç•¥
