---
title: Crews å›¢é˜Ÿç¼–æ’
description: Crew æ ¸å¿ƒå±æ€§ã€è£…é¥°å™¨æ¨¡å¼ã€è¾“å‡ºå¤„ç†ã€åŒæ­¥ä¸å¼‚æ­¥å¯åŠ¨æ–¹å¼
---

# ğŸ”¥ Crews å›¢é˜Ÿç¼–æ’

> Crew æ˜¯ Agent çš„**åä½œå›¢é˜Ÿ**â€”â€”å°†å¤šä¸ª Agent å’Œ Task ç»„è£…åœ¨ä¸€èµ·ï¼Œå®šä¹‰æ‰§è¡Œæµç¨‹ï¼Œå…±åŒå®Œæˆå¤æ‚ä»»åŠ¡ã€‚

## 1. Crew æ ¸å¿ƒå±æ€§

| å±æ€§ | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `agents` | `List[Agent]` | **å¿…å¡«** | Agent åˆ—è¡¨ |
| `tasks` | `List[Task]` | **å¿…å¡«** | Task åˆ—è¡¨ |
| `process` | `Process` | `sequential` | æ‰§è¡Œæµç¨‹ï¼ˆé¡ºåº/å±‚çº§ï¼‰ |
| `verbose` | `bool` | `False` | è¯¦ç»†æ—¥å¿— |
| `memory` | `bool` | `None` | å¯ç”¨è®°å¿†ç³»ç»Ÿ |
| `cache` | `bool` | `True` | ç¼“å­˜å·¥å…·ç»“æœ |
| `planning` | `bool` | `None` | å¯ç”¨è§„åˆ’èƒ½åŠ› |
| `planning_llm` | `str` | `None` | è§„åˆ’ä¸“ç”¨ LLM |
| `manager_llm` | `str` | `None` | å±‚çº§æµç¨‹ç®¡ç†è€… LLM |
| `manager_agent` | `Agent` | `None` | è‡ªå®šä¹‰ç®¡ç†è€… Agent |
| `knowledge_sources` | `List` | `None` | çŸ¥è¯†æº |
| `embedder` | `Dict` | `{"provider":"openai"}` | åµŒå…¥æ¨¡å‹é…ç½® |
| `stream` | `bool` | `False` | æµå¼è¾“å‡º |

## 2. åˆ›å»º Crew

### 2.1 åŸºç¡€æ–¹å¼

```python
from crewai import Agent, Task, Crew, Process

crew = Crew(
    agents=[researcher, analyst, writer],
    tasks=[research_task, analysis_task, writing_task],
    process=Process.sequential,
    verbose=True
)

result = crew.kickoff(inputs={"topic": "AI Agent"})
```

### 2.2 è£…é¥°å™¨æ¨¡å¼ï¼ˆæ¨èç”¨äºæ­£å¼é¡¹ç›®ï¼‰

```python
from crewai import Agent, Crew, Task, Process
from crewai.project import CrewBase, agent, task, crew
from crewai.project import before_kickoff, after_kickoff

@CrewBase
class ResearchCrew:
    """ç ”ç©¶åˆ†æå›¢é˜Ÿ"""
    agents_config = 'config/agents.yaml'
    tasks_config = 'config/tasks.yaml'

    @before_kickoff
    def prepare(self, inputs):
        """å¯åŠ¨å‰é¢„å¤„ç†"""
        inputs['timestamp'] = '2025-01-01'
        return inputs

    @after_kickoff
    def process(self, output):
        """å®Œæˆååå¤„ç†"""
        print(f"æ€» Token: {output.token_usage}")
        return output

    @agent
    def researcher(self) -> Agent:
        return Agent(
            config=self.agents_config['researcher'],
            verbose=True
        )

    @agent
    def analyst(self) -> Agent:
        return Agent(
            config=self.agents_config['analyst'],
            verbose=True
        )

    @task
    def research_task(self) -> Task:
        return Task(config=self.tasks_config['research_task'])

    @task
    def analysis_task(self) -> Task:
        return Task(config=self.tasks_config['analysis_task'])

    @crew
    def crew(self) -> Crew:
        return Crew(
            agents=self.agents,   # @agent è‡ªåŠ¨æ”¶é›†
            tasks=self.tasks,     # @task è‡ªåŠ¨æ”¶é›†
            process=Process.sequential,
            verbose=True
        )
```

> `@agent` å’Œ `@task` è£…é¥°çš„æ–¹æ³•ä¼šè¢«è‡ªåŠ¨æ”¶é›†åˆ° `self.agents` å’Œ `self.tasks` ä¸­ã€‚

## 3. Crew æ‰§è¡Œæµç¨‹

```mermaid
flowchart TB
    K["kickoff(inputs)"] --> BK["@before_kickoff<br/>é¢„å¤„ç†"]
    BK --> P{"Process?"}
    P -->|sequential| S["æŒ‰é¡ºåºæ‰§è¡Œ Task"]
    P -->|hierarchical| H["ç®¡ç†è€…åˆ†é… Task"]
    S --> T1["Task 1 â†’ Agent 1"]
    T1 --> T2["Task 2 â†’ Agent 2<br/>ï¼ˆå« Task 1 ä¸Šä¸‹æ–‡ï¼‰"]
    T2 --> T3["Task 3 â†’ Agent 3<br/>ï¼ˆå« Task 2 ä¸Šä¸‹æ–‡ï¼‰"]
    H --> M["Manager Agent"]
    M --> T1H["åˆ†é… Task â†’ Agent"]
    T1H --> M
    T3 --> AK["@after_kickoff<br/>åå¤„ç†"]
    M --> AK
    AK --> R["è¿”å› CrewOutput"]

    style K fill:#e8f4f8,stroke:#0ea5e9
    style R fill:#dcfce7,stroke:#22c55e
```

## 4. è¾“å‡ºå¤„ç†

### 4.1 CrewOutput å±æ€§

| å±æ€§ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `raw` | `str` | æœ€ç»ˆ Task çš„åŸå§‹æ–‡æœ¬è¾“å‡º |
| `pydantic` | `BaseModel \| None` | ç»“æ„åŒ–å¯¹è±¡ï¼ˆéœ€æœ€ç»ˆ Task é…ç½®ï¼‰ |
| `json_dict` | `dict \| None` | JSON å­—å…¸ |
| `tasks_output` | `List[TaskOutput]` | æ¯ä¸ª Task çš„è¾“å‡ºåˆ—è¡¨ |
| `token_usage` | `Dict` | Token ä½¿ç”¨ç»Ÿè®¡ |

```python
result = crew.kickoff(inputs={"topic": "AI"})

# è®¿é—®æœ€ç»ˆç»“æœ
print(result.raw)

# è®¿é—®æ¯ä¸ªä»»åŠ¡çš„è¾“å‡º
for i, task_out in enumerate(result.tasks_output):
    print(f"ä»»åŠ¡ {i+1}: {task_out.raw[:100]}...")

# Token ç»Ÿè®¡
print(f"æ€» Token: {result.token_usage}")
```

### 4.2 æµå¼è¾“å‡º

```python
crew = Crew(
    agents=[researcher],
    tasks=[research_task],
    stream=True  # å¯ç”¨æµå¼
)

streaming = crew.kickoff(inputs={"topic": "AI"})
for chunk in streaming:
    print(chunk.content, end="", flush=True)

# è·å–æœ€ç»ˆç»“æœ
final_result = streaming.result
```

## 5. å¯åŠ¨æ–¹å¼

| æ–¹æ³• | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `kickoff()` | åŒæ­¥ | æ ‡å‡†å¯åŠ¨ï¼Œé˜»å¡ç­‰å¾…ç»“æœ |
| `kickoff_for_each()` | åŒæ­¥æ‰¹é‡ | å¯¹è¾“å…¥åˆ—è¡¨é€ä¸€æ‰§è¡Œ |
| `akickoff()` | åŸç”Ÿå¼‚æ­¥ | å…¨é“¾è·¯ async/await |
| `akickoff_for_each()` | å¼‚æ­¥æ‰¹é‡ | åˆ—è¡¨è¾“å…¥åŸç”Ÿå¼‚æ­¥ |

### 5.1 æ‰¹é‡æ‰§è¡Œ

```python
inputs = [
    {"topic": "AI Agent"},
    {"topic": "RAG æŠ€æœ¯"},
    {"topic": "å¤šæ¨¡æ€ AI"}
]

results = crew.kickoff_for_each(inputs=inputs)
for result in results:
    print(result.raw[:100])
```

### 5.2 å¼‚æ­¥æ‰§è¡Œ

```python
import asyncio

async def main():
    result = await crew.akickoff(inputs={"topic": "AI"})
    print(result.raw)

asyncio.run(main())
```

## 6. å¯ç”¨é«˜çº§åŠŸèƒ½

```python
crew = Crew(
    agents=[researcher, analyst],
    tasks=[research_task, analysis_task],
    process=Process.sequential,
    memory=True,         # å¯ç”¨è®°å¿†
    planning=True,       # å¯ç”¨è§„åˆ’
    planning_llm="openai/gpt-4o",  # è§„åˆ’ç”¨ LLM
    verbose=True
)
```

---

**å…ˆä¿®**ï¼š[Tasks ä»»åŠ¡](/ai/crewai/guide/tasks)

**ä¸‹ä¸€æ­¥**ï¼š
- [Flows å·¥ä½œæµ](/ai/crewai/guide/flows) â€” ç”¨ Flow ç¼–æ’å¤šä¸ª Crew
- [Processes æ‰§è¡Œæµç¨‹](/ai/crewai/guide/processes) â€” æ·±å…¥ç†è§£é¡ºåºä¸å±‚çº§æµç¨‹

**å‚è€ƒ**ï¼š
- [ğŸ”— CrewAI Crews (Official)](https://docs.crewai.com/en/concepts/crews){target="_blank" rel="noopener"}
