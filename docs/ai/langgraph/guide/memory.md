---
title: Memory è®°å¿†ç³»ç»Ÿ
description: çŸ­æœŸè®°å¿†ä¸é•¿æœŸè®°å¿† â€” ä»ç»„ä»¶ state åˆ° IndexedDBï¼ŒLangGraph çš„è®°å¿†æ¶æ„å…¨è§£
---

# Memory è®°å¿†ç³»ç»Ÿ

> Agent æ²¡æœ‰è®°å¿†å°±åƒ React ç»„ä»¶æ²¡æœ‰ stateâ€”â€”æ¯æ¬¡æ¸²æŸ“éƒ½æ˜¯å…¨æ–°çš„ã€‚LangGraph çš„ Memory ç³»ç»Ÿè®© Agent æ—¢èƒ½"è®°ä½ä¸Šä¸‹æ–‡"ï¼ˆçŸ­æœŸï¼‰ï¼Œåˆèƒ½"è®°ä½ç”¨æˆ·åå¥½"ï¼ˆé•¿æœŸï¼‰ã€‚

## å‰ç«¯ç±»æ¯”ï¼šå…ˆå»ºç«‹ç›´è§‰

| å‰ç«¯æ¦‚å¿µ | LangGraph æ¦‚å¿µ | è¯´æ˜ |
|---------|---------------|------|
| `useState` / ç»„ä»¶ state | çŸ­æœŸè®°å¿† (Checkpoint) | å½“å‰ä¼šè¯å†…çš„ä¸Šä¸‹æ–‡ |
| `useRef` è·¨æ¸²æŸ“æŒä¹…å€¼ | Thread å†…å¤šè½®è®°å¿† | å¯¹è¯å†å²åœ¨åŒä¸€ thread ä¸­ä¿ç•™ |
| IndexedDB / åç«¯æ•°æ®åº“ | é•¿æœŸè®°å¿† (Store) | è·¨ä¼šè¯æŒä¹…åŒ–çš„ç”¨æˆ·æ•°æ® |
| Context API | Store namespace | æŒ‰ä½œç”¨åŸŸç»„ç»‡æ•°æ® |
| æœç´¢å¼•æ“å…¨æ–‡æ£€ç´¢ | è¯­ä¹‰æœç´¢ | åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢è®°å¿† |

**LangGraph åŸç”Ÿè¯­ä¹‰**ï¼šLangGraph çš„è®°å¿†åˆ†ä¸¤å±‚â€”â€”**çŸ­æœŸè®°å¿†**é€šè¿‡ Checkpointer å®ç°ï¼Œå­˜åœ¨ checkpoint çš„ state ä¸­ï¼ˆåŒä¸€ thread çš„å¤šè½®å¯¹è¯ï¼‰ï¼›**é•¿æœŸè®°å¿†**é€šè¿‡ Store å®ç°ï¼ŒæŒ‰ namespace éš”ç¦»ï¼Œæ”¯æŒè¯­ä¹‰æœç´¢ï¼ˆè·¨ thread çš„ç”¨æˆ·åå¥½ã€çŸ¥è¯†ï¼‰ã€‚

[ğŸ”— Memory å®˜æ–¹æ¦‚å¿µæ–‡æ¡£](https://langchain-ai.github.io/langgraph/concepts/memory/){target="_blank" rel="noopener"}

---

## 1. çŸ­æœŸè®°å¿† (Short-term Memory)

### ä»€ä¹ˆæ˜¯çŸ­æœŸè®°å¿†

çŸ­æœŸè®°å¿†å°±æ˜¯**åŒä¸€ä¸ª thread å†…çš„å¯¹è¯ä¸Šä¸‹æ–‡**ã€‚å®ƒè‡ªåŠ¨å­˜å‚¨åœ¨ checkpoint çš„ state ä¸­ã€‚

```mermaid
flowchart LR
    subgraph thread["Thread: user-session-1"]
        M1["Turn 1: ä½ å¥½"] --> M2["Turn 2: æˆ‘å« Alice"]
        M2 --> M3["Turn 3: æˆ‘å«ä»€ä¹ˆï¼Ÿ"]
        M3 --> M4["Agent: ä½ å« Alice"]
    end

    CP["Checkpoint<br/>ä¿å­˜å®Œæ•´æ¶ˆæ¯å†å²"]
    thread -.->|"æ¯è½®è‡ªåŠ¨ä¿å­˜"| CP

    style CP fill:#4CAF50,color:#fff
```

### æ·»åŠ çŸ­æœŸè®°å¿†

ä½¿ç”¨ `MessagesState`ï¼Œæ¶ˆæ¯å†å²è‡ªåŠ¨ç´¯ç§¯ï¼š

```python
from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.checkpoint.memory import InMemorySaver
from langchain.chat_models import init_chat_model

model = init_chat_model("gpt-4.1-mini")

def chatbot(state: MessagesState):
    """æ¶ˆæ¯åˆ—è¡¨è‡ªåŠ¨åŒ…å«å®Œæ•´å†å²ï¼ŒLLM èƒ½çœ‹åˆ°æ‰€æœ‰ä¸Šä¸‹æ–‡"""
    response = model.invoke(state["messages"])
    return {"messages": [response]}

builder = StateGraph(MessagesState)
builder.add_node("chat", chatbot)
builder.add_edge(START, "chat")
builder.add_edge("chat", END)

# å¿…é¡»æŒ‚ checkpointer æ‰æœ‰çŸ­æœŸè®°å¿†
checkpointer = InMemorySaver()
graph = builder.compile(checkpointer=checkpointer)

config = {"configurable": {"thread_id": "alice-session-1"}}

# ç¬¬ä¸€è½®
graph.invoke({"messages": [{"role": "user", "content": "ä½ å¥½ï¼Œæˆ‘å« Alice"}]}, config)

# ç¬¬äºŒè½® â€” ä¼ å…¥æ–°æ¶ˆæ¯ï¼ŒLangGraph è‡ªåŠ¨åˆå¹¶å†å²
result = graph.invoke({"messages": [{"role": "user", "content": "æˆ‘å«ä»€ä¹ˆï¼Ÿ"}]}, config)
print(result["messages"][-1].content)
# "ä½ å« Alice"
```

**å‰ç«¯ç±»æ¯”**ï¼šè¿™å°±åƒ React ä¸­ `useState` ç®¡ç†çš„èŠå¤©è®°å½•â€”â€”æ–°æ¶ˆæ¯ append åˆ°æ•°ç»„é‡Œï¼Œç»„ä»¶é‡æ–°æ¸²æŸ“æ—¶æ€»èƒ½çœ‹åˆ°å®Œæ•´å†å²ã€‚åŒºåˆ«æ˜¯ LangGraph æŠŠè¿™ä¸ª state æŒä¹…åŒ–äº†ï¼Œå³ä½¿è¿›ç¨‹é‡å¯ä¹Ÿä¸ä¸¢å¤±ã€‚

### ç”Ÿäº§ç¯å¢ƒä½¿ç”¨

åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œä½¿ç”¨æŒä¹…åŒ– checkpointer ä¿è¯çŸ­æœŸè®°å¿†ä¸ä¸¢å¤±ï¼š

```python
from langgraph.checkpoint.postgres import PostgresSaver

DB_URI = "postgresql://user:pass@localhost:5432/mydb"

with PostgresSaver.from_conn_string(DB_URI) as checkpointer:
    graph = builder.compile(checkpointer=checkpointer)

    # å³ä½¿æœåŠ¡é‡å¯ï¼ŒåŒä¸€ thread_id çš„å¯¹è¯å†å²ä»ç„¶å®Œæ•´
    config = {"configurable": {"thread_id": "alice-session-1"}}
    result = graph.invoke(
        {"messages": [{"role": "user", "content": "ç»§ç»­ä¸Šæ¬¡çš„è¯é¢˜"}]},
        config
    )
```

### åœ¨ Subgraph ä¸­ä½¿ç”¨çŸ­æœŸè®°å¿†

å­å›¾é»˜è®¤å…±äº«çˆ¶å›¾çš„ checkpointï¼ˆé€šè¿‡ `MessagesState` çš„ `messages` key ä¼ é€’ï¼‰ï¼š

```python
from langgraph.graph import StateGraph, MessagesState, START, END

# å­å›¾
def sub_node(state: MessagesState):
    # å­å›¾èƒ½çœ‹åˆ°ä»çˆ¶å›¾ä¼ å…¥çš„æ¶ˆæ¯å†å²
    history_len = len(state["messages"])
    return {"messages": [{"role": "assistant", "content": f"å­å›¾æ”¶åˆ° {history_len} æ¡æ¶ˆæ¯"}]}

sub_builder = StateGraph(MessagesState)
sub_builder.add_node("process", sub_node)
sub_builder.add_edge(START, "process")
sub_builder.add_edge("process", END)
sub_graph = sub_builder.compile()

# ä¸»å›¾
def main_node(state: MessagesState):
    return {"messages": [{"role": "assistant", "content": "ä¸»å›¾å¤„ç†"}]}

main_builder = StateGraph(MessagesState)
main_builder.add_node("main", main_node)
main_builder.add_node("sub", sub_graph)
main_builder.add_edge(START, "main")
main_builder.add_edge("main", "sub")
main_builder.add_edge("sub", END)

checkpointer = InMemorySaver()
graph = main_builder.compile(checkpointer=checkpointer)
```

---

## 2. é•¿æœŸè®°å¿† (Long-term Memory)

### ä»€ä¹ˆæ˜¯é•¿æœŸè®°å¿†

é•¿æœŸè®°å¿†å­˜å‚¨åœ¨ **Store** ä¸­ï¼Œå®ƒæ˜¯**è·¨ thread çš„æŒä¹…åŒ– key-value å­˜å‚¨**ã€‚[ğŸ”— Store ä¸é•¿æœŸè®°å¿†æŒ‡å—](https://langchain-ai.github.io/langgraph/how-tos/cross-thread-persistence/){target="_blank" rel="noopener"} é€‚åˆå­˜å‚¨ï¼š

- ç”¨æˆ·åå¥½å’Œé…ç½®
- å­¦åˆ°çš„çŸ¥è¯†å’Œäº‹å®
- å†å²äº¤äº’æ¨¡å¼çš„æ€»ç»“

```mermaid
flowchart TB
    subgraph threads["ä¸åŒ Threadï¼ˆä¼šè¯ï¼‰"]
        T1["Thread 1: æ—©ä¸Šçš„å¯¹è¯"]
        T2["Thread 2: ä¸‹åˆçš„å¯¹è¯"]
        T3["Thread 3: ç¬¬äºŒå¤©çš„å¯¹è¯"]
    end

    subgraph store["Storeï¼ˆé•¿æœŸè®°å¿†ï¼‰"]
        NS["namespace: ('users', 'alice')"]
        NS --> K1["key: preferences<br/>theme=dark, lang=zh"]
        NS --> K2["key: facts<br/>likes TypeScript"]
        NS --> K3["key: history_summary<br/>è®¨è®ºè¿‡ LangGraph"]
    end

    T1 -.->|"å†™å…¥"| store
    T2 -.->|"è¯»+å†™"| store
    T3 -.->|"è¯»+å†™"| store

    style store fill:#e3f2fd
```

### åœ¨èŠ‚ç‚¹ä¸­è®¿é—® Store

```python
from dataclasses import dataclass
from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.store.memory import InMemoryStore
from langgraph.runtime import Runtime

@dataclass
class UserContext:
    user_id: str

store = InMemoryStore()
checkpointer = InMemorySaver()

# é¢„å­˜ä¸€äº›ç”¨æˆ·åå¥½
store.put(("users", "alice"), "preferences", {"language": "zh-CN", "style": "concise"})

def personalized_response(state: MessagesState, runtime: Runtime[UserContext]):
    """æ ¹æ®é•¿æœŸè®°å¿†ä¸ªæ€§åŒ–å›å¤"""
    user_id = runtime.context.user_id

    # è¯»å–ç”¨æˆ·åå¥½
    prefs = runtime.store.get(("users", user_id), "preferences")
    if prefs:
        language = prefs.value.get("language", "en")
        style = prefs.value.get("style", "normal")
        context = f"ç”¨æˆ·åå¥½è¯­è¨€={language}ï¼Œé£æ ¼={style}"
    else:
        context = "æ— å·²çŸ¥åå¥½"

    return {
        "messages": [{
            "role": "assistant",
            "content": f"[{context}] åŸºäºä½ çš„åå¥½å›å¤..."
        }]
    }

def learn_from_conversation(state: MessagesState, runtime: Runtime[UserContext]):
    """ä»å¯¹è¯ä¸­æå–ä¿¡æ¯å­˜å…¥é•¿æœŸè®°å¿†"""
    user_id = runtime.context.user_id

    last_msg = state["messages"][-1]
    # ç®€åŒ–ç¤ºä¾‹ï¼šå®é™…ä¸­ä½ ä¼šç”¨ LLM æ¥æå–å…³é”®ä¿¡æ¯
    runtime.store.put(
        ("users", user_id),
        f"fact-{len(state['messages'])}",
        {"content": last_msg.content, "type": "learned_fact"}
    )
    return state

builder = StateGraph(MessagesState, context_schema=UserContext)
builder.add_node("respond", personalized_response)
builder.add_node("learn", learn_from_conversation)
builder.add_edge(START, "respond")
builder.add_edge("respond", "learn")
builder.add_edge("learn", END)

graph = builder.compile(checkpointer=checkpointer, store=store)
```

### ç”Ÿäº§ç¯å¢ƒä½¿ç”¨

åœ¨ç”Ÿäº§ä¸­ï¼ŒStore åº”ä½¿ç”¨æŒä¹…åŒ–åç«¯ï¼š

```python
# å½“å‰ LangGraph æä¾› InMemoryStore
# ç”Ÿäº§ç¯å¢ƒå»ºè®®æ­é… LangGraph Platform æˆ–è‡ªå®šä¹‰ Store å®ç°
from langgraph.store.memory import InMemoryStore

# InMemoryStore æ”¯æŒé…ç½®å‘é‡åµŒå…¥ä»¥å¯ç”¨è¯­ä¹‰æœç´¢
store = InMemoryStore(
    index={
        "embed": "openai:text-embedding-3-small",
        "dims": 1536,
        "fields": ["text"]
    }
)
```

### è¯­ä¹‰æœç´¢

å½“é•¿æœŸè®°å¿†ä¸­å­˜å‚¨äº†å¤§é‡éç»“æ„åŒ–æ–‡æœ¬æ—¶ï¼Œè¯­ä¹‰æœç´¢æ¯”ç²¾ç¡®åŒ¹é…æ›´æœ‰ç”¨ï¼š

```python
from langgraph.store.memory import InMemoryStore

store = InMemoryStore(
    index={
        "embed": "openai:text-embedding-3-small",
        "dims": 1536,
        "fields": ["text"],
    }
)

# å­˜å…¥å¤šæ¡è®°å¿†
memories = [
    ("mem-1", {"text": "ç”¨æˆ·æ˜¯ä¸€ä½å‰ç«¯å·¥ç¨‹å¸ˆï¼Œæ“…é•¿ React å’Œ TypeScript"}),
    ("mem-2", {"text": "ç”¨æˆ·å¯¹ Python çš„è£…é¥°å™¨è¯­æ³•æœ‰å›°æƒ‘"}),
    ("mem-3", {"text": "ç”¨æˆ·çš„é¡¹ç›®ä½¿ç”¨ FastAPI ä½œä¸ºåç«¯æ¡†æ¶"}),
    ("mem-4", {"text": "ç”¨æˆ·å–œæ¬¢ç®€æ´çš„ä»£ç é£æ ¼ï¼Œä¸å–œæ¬¢è¿‡åº¦æŠ½è±¡"}),
    ("mem-5", {"text": "ç”¨æˆ·å®¶é‡Œå…»äº†ä¸¤åªçŒ«"}),
]

for key, value in memories:
    store.put(("users", "bob"), key, value)

# è¯­ä¹‰æœç´¢ï¼šæ‰¾åˆ°ä¸"ç¼–ç¨‹èƒŒæ™¯"ç›¸å…³çš„è®°å¿†
results = store.search(
    ("users", "bob"),
    query="è¿™ä¸ªç”¨æˆ·çš„ç¼–ç¨‹æŠ€æœ¯èƒŒæ™¯æ˜¯ä»€ä¹ˆ",
    limit=3
)

for r in results:
    print(f"  [score={r.score:.2f}] {r.value['text']}")
# å¯èƒ½è¾“å‡ºï¼š
# [score=0.91] ç”¨æˆ·æ˜¯ä¸€ä½å‰ç«¯å·¥ç¨‹å¸ˆï¼Œæ“…é•¿ React å’Œ TypeScript
# [score=0.82] ç”¨æˆ·çš„é¡¹ç›®ä½¿ç”¨ FastAPI ä½œä¸ºåç«¯æ¡†æ¶
# [score=0.75] ç”¨æˆ·å¯¹ Python çš„è£…é¥°å™¨è¯­æ³•æœ‰å›°æƒ‘
```

**å‰ç«¯ç±»æ¯”**ï¼šè¿™ç±»ä¼¼äºåœ¨ Algolia æˆ– ElasticSearch ä¸­åšå…¨æ–‡æœç´¢ï¼Œä½†åŸºäºè¯­ä¹‰å‘é‡è€Œä¸æ˜¯å…³é”®è¯åŒ¹é…ã€‚"ç¼–ç¨‹èƒŒæ™¯"èƒ½åŒ¹é…åˆ°"React å’Œ TypeScript"ï¼Œå³ä½¿ä¸¤è€…æ²¡æœ‰å…±åŒå…³é”®è¯ã€‚

---

## 3. ç®¡ç†çŸ­æœŸè®°å¿†

éšç€å¯¹è¯è½®æ•°å¢åŠ ï¼Œæ¶ˆæ¯å†å²ä¼šå˜å¾—å¾ˆé•¿ï¼Œå¯¼è‡´ï¼š
- LLM ä¸Šä¸‹æ–‡çª—å£æº¢å‡º
- æ¨ç†è´¨é‡ä¸‹é™ï¼ˆä¿¡æ¯è¿‡è½½ï¼‰
- Token æˆæœ¬å¢åŠ 

### è£å‰ªæ¶ˆæ¯ (Trim)

```python
from langchain_core.messages import trim_messages

def chatbot_with_trim(state: MessagesState):
    """è£å‰ªæ¶ˆæ¯å†å²ï¼Œåªä¿ç•™æœ€è¿‘çš„æ¶ˆæ¯"""
    # åªä¿ç•™æœ€è¿‘ 10 æ¡æ¶ˆæ¯ï¼ˆæˆ–æœ€è¿‘ 4000 tokensï¼‰
    trimmed = trim_messages(
        state["messages"],
        max_tokens=4000,
        strategy="last",  # ä¿ç•™æœ€åçš„æ¶ˆæ¯
        token_counter=len,  # ç®€åŒ–çš„ token è®¡æ•°å™¨
        include_system=True,  # å§‹ç»ˆä¿ç•™ system æ¶ˆæ¯
    )

    response = model.invoke(trimmed)
    return {"messages": [response]}
```

**å‰ç«¯ç±»æ¯”**ï¼šç±»ä¼¼äº React è™šæ‹Ÿåˆ—è¡¨â€”â€”åˆ—è¡¨å¯èƒ½æœ‰ 10000 é¡¹ï¼Œä½† DOM ä¸­åªæ¸²æŸ“å¯è§çš„ 20 é¡¹ã€‚è¿™é‡Œæ˜¯æ¶ˆæ¯å¯èƒ½æœ‰ 100 è½®ï¼Œä½†å‘ç»™ LLM çš„åªæœ‰æœ€è¿‘ 10 è½®ã€‚

### åˆ é™¤æ¶ˆæ¯

```python
from langchain_core.messages import RemoveMessage

def cleanup_messages(state: MessagesState):
    """åˆ é™¤ç‰¹å®šæ¶ˆæ¯"""
    messages_to_remove = []
    for msg in state["messages"]:
        # åˆ é™¤æ‰€æœ‰å·¥å…·è°ƒç”¨æ¶ˆæ¯ï¼ˆå‡å°‘å™ªéŸ³ï¼‰
        if msg.type == "tool":
            messages_to_remove.append(RemoveMessage(id=msg.id))

    return {"messages": messages_to_remove}
```

### æ€»ç»“æ¶ˆæ¯

å°†å†—é•¿çš„å¯¹è¯å†å²å‹ç¼©ä¸ºä¸€æ¡æ€»ç»“æ¶ˆæ¯ï¼š

```python
from langchain_core.messages import RemoveMessage

def summarize_conversation(state: MessagesState):
    """å°†å†å²æ¶ˆæ¯æ€»ç»“ä¸ºä¸€æ¡ï¼Œå‡å°‘ä¸Šä¸‹æ–‡é•¿åº¦"""
    if len(state["messages"]) <= 10:
        return state  # æ¶ˆæ¯ä¸å¤šï¼Œä¸éœ€è¦æ€»ç»“

    # ç”¨ LLM ç”Ÿæˆæ€»ç»“
    summary_prompt = (
        "è¯·ç”¨ 2-3 å¥è¯æ€»ç»“ä»¥ä¸‹å¯¹è¯çš„å…³é”®ä¿¡æ¯ï¼š\n\n"
        + "\n".join(
            f"{m.type}: {m.content}" for m in state["messages"][:-2]
        )
    )
    summary = model.invoke([{"role": "user", "content": summary_prompt}])

    # åˆ é™¤æ—§æ¶ˆæ¯ï¼Œä¿ç•™æ€»ç»“ + æœ€è¿‘ 2 æ¡
    remove_msgs = [
        RemoveMessage(id=m.id) for m in state["messages"][:-2]
    ]

    # æ’å…¥æ€»ç»“æ¶ˆæ¯
    summary_message = {
        "role": "system",
        "content": f"ä¹‹å‰å¯¹è¯çš„æ€»ç»“ï¼š{summary.content}"
    }

    return {"messages": remove_msgs + [summary_message]}
```

```mermaid
flowchart LR
    subgraph before["æ€»ç»“å‰ (20 æ¡æ¶ˆæ¯)"]
        B1["msg 1"] --> B2["msg 2"] --> B3["..."] --> B20["msg 20"]
    end

    subgraph after["æ€»ç»“å (3 æ¡æ¶ˆæ¯)"]
        A1["system: ä¹‹å‰å¯¹è¯çš„æ€»ç»“..."] --> A2["msg 19"] --> A3["msg 20"]
    end

    before -->|"summarize"| after

    style before fill:#fff3e0
    style after fill:#e8f5e9
```

### ç®¡ç† Checkpoints

å¯¹äºé•¿æœŸè¿è¡Œçš„ threadï¼Œcheckpoint ä¹Ÿéœ€è¦ç®¡ç†ï¼š

```python
# æŸ¥çœ‹ checkpoint å ç”¨æƒ…å†µ
checkpoint_count = 0
for _ in graph.get_state_history(config):
    checkpoint_count += 1

print(f"å½“å‰ thread æœ‰ {checkpoint_count} ä¸ª checkpoint")

# åœ¨ç”Ÿäº§ä¸­ï¼Œå¯ä»¥é€šè¿‡ checkpointer çš„åº•å±‚æ¥å£æ¸…ç†æ—§ checkpoint
# PostgresSaver å¯ä»¥é€šè¿‡ SQL æ¸…ç†ï¼š
# DELETE FROM checkpoints WHERE thread_id = 'xxx' AND created_at < '2024-01-01'
```

---

## 4. è®°å¿†ç³»ç»Ÿæ¶æ„å…¨æ™¯

```mermaid
flowchart TB
    subgraph app["LangGraph Application"]
        subgraph short["çŸ­æœŸè®°å¿†"]
            MSG["MessagesState<br/>æ¶ˆæ¯å†å²"]
            TRIM["trim_messages<br/>è£å‰ª"]
            SUM["summarize<br/>æ€»ç»“"]
            MSG --> TRIM
            MSG --> SUM
        end

        subgraph long["é•¿æœŸè®°å¿†"]
            STORE["Store"]
            NS1["namespace: users/alice"]
            NS2["namespace: users/bob"]
            SEM["è¯­ä¹‰æœç´¢<br/>embedding index"]
            STORE --> NS1
            STORE --> NS2
            STORE --> SEM
        end

        short -.->|"å…³é”®ä¿¡æ¯æå–"| long
        long -.->|"æ³¨å…¥ä¸Šä¸‹æ–‡"| short
    end

    subgraph persistence["æŒä¹…åŒ–å±‚"]
        CKP["Checkpointer<br/>Postgres / SQLite"]
        DB["Store Backend<br/>InMemory / è‡ªå®šä¹‰"]
    end

    short -->|"ä¿å­˜åœ¨"| CKP
    long -->|"ä¿å­˜åœ¨"| DB
```

### çŸ­æœŸä¸é•¿æœŸè®°å¿†çš„åä½œ

å…¸å‹çš„å·¥ä½œæµæ˜¯ï¼š

1. **çŸ­æœŸè®°å¿†**æ‰¿è½½å½“å‰å¯¹è¯ä¸Šä¸‹æ–‡
2. ä»çŸ­æœŸè®°å¿†ä¸­**æå–å…³é”®ä¿¡æ¯**å†™å…¥é•¿æœŸè®°å¿†
3. æ–°å¯¹è¯å¼€å§‹æ—¶ï¼Œä»é•¿æœŸè®°å¿†**æ³¨å…¥ä¸ªæ€§åŒ–ä¸Šä¸‹æ–‡**

```python
from dataclasses import dataclass
from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.store.memory import InMemoryStore
from langgraph.runtime import Runtime

@dataclass
class UserContext:
    user_id: str

def inject_long_term_memory(state: MessagesState, runtime: Runtime[UserContext]):
    """å¯¹è¯å¼€å§‹æ—¶æ³¨å…¥é•¿æœŸè®°å¿†"""
    user_id = runtime.context.user_id
    # æœç´¢ä¸å½“å‰è¯é¢˜ç›¸å…³çš„è®°å¿†
    last_user_msg = state["messages"][-1].content if state["messages"] else ""
    memories = runtime.store.search(
        ("users", user_id),
        query=last_user_msg,
        limit=3
    )

    if memories:
        context = "\n".join(m.value.get("text", "") for m in memories)
        system_msg = {
            "role": "system",
            "content": f"ç”¨æˆ·çš„å†å²ä¿¡æ¯ï¼š\n{context}"
        }
        return {"messages": [system_msg]}
    return state

def extract_to_long_term(state: MessagesState, runtime: Runtime[UserContext]):
    """å¯¹è¯ç»“æŸæ—¶æå–å…³é”®ä¿¡æ¯åˆ°é•¿æœŸè®°å¿†"""
    user_id = runtime.context.user_id

    # ç”¨æœ€åä¸€è½®äº¤äº’å†…å®¹å­˜å…¥é•¿æœŸè®°å¿†
    if len(state["messages"]) >= 2:
        last_exchange = state["messages"][-2:]
        content = " | ".join(m.content for m in last_exchange if hasattr(m, "content"))
        runtime.store.put(
            ("users", user_id),
            f"conv-{len(state['messages'])}",
            {"text": content}
        )
    return state
```

---

## 5. æ•°æ®åº“ç®¡ç†

### å­˜å‚¨é€‰å‹

| éœ€æ±‚ | çŸ­æœŸè®°å¿†æ–¹æ¡ˆ | é•¿æœŸè®°å¿†æ–¹æ¡ˆ |
|------|------------|------------|
| æœ¬åœ°å¼€å‘ | `InMemorySaver` | `InMemoryStore` |
| å°è§„æ¨¡ç”Ÿäº§ | `SqliteSaver` | `InMemoryStore` + å®šæœŸå¯¼å‡º |
| å¤§è§„æ¨¡ç”Ÿäº§ | `PostgresSaver` | è‡ªå®šä¹‰ Storeï¼ˆPostgres/Redisï¼‰ |
| éœ€è¦è¯­ä¹‰æœç´¢ | N/A | `InMemoryStore(index={...})` |

### æ•°æ®å®‰å…¨

```python
# å¯¹æ•æ„Ÿè®°å¿†æ•°æ®åŠ å¯†å­˜å‚¨
from langgraph.checkpoint.serde.encrypted import EncryptedSerializer
import os

os.environ["LANGGRAPH_AES_KEY"] = "your-aes-256-key"
serde = EncryptedSerializer.from_pycryptodome_aes()

# Checkpoint åŠ å¯†
from langgraph.checkpoint.sqlite import SqliteSaver
import sqlite3
encrypted_checkpointer = SqliteSaver(sqlite3.connect("secure.db"), serde=serde)
```

### æ•°æ®éš”ç¦»

```python
# æŒ‰ç”¨æˆ·éš”ç¦» namespace
def get_user_namespace(user_id: str):
    return ("users", user_id)

# æŒ‰ç§Ÿæˆ· + ç”¨æˆ·éš”ç¦»
def get_tenant_user_namespace(tenant_id: str, user_id: str):
    return ("tenants", tenant_id, "users", user_id)

# å†™å…¥
store.put(
    get_tenant_user_namespace("company-a", "alice"),
    "preferences",
    {"theme": "dark"}
)

# æœç´¢æ—¶åªèƒ½çœ‹åˆ°è‡ªå·± namespace ä¸‹çš„æ•°æ®
results = store.search(
    get_tenant_user_namespace("company-a", "alice"),
    query="åå¥½"
)
```

### æ•°æ®ç”Ÿå‘½å‘¨æœŸ

```python
# çŸ­æœŸè®°å¿†ç®¡ç†
# - æ´»è·ƒ threadï¼šä¿ç•™å®Œæ•´ checkpoint é“¾
# - ä¸æ´»è·ƒ threadï¼ˆ>30 å¤©ï¼‰ï¼šåªä¿ç•™æœ€ç»ˆ checkpoint
# - å·²å®Œæˆ threadï¼ˆ>90 å¤©ï¼‰ï¼šå½’æ¡£ååˆ é™¤

# é•¿æœŸè®°å¿†ç®¡ç†
# - å®šæœŸè¯„ä¼°è®°å¿†çš„"æ–°é²œåº¦"
# - è¿‡æ—¶çš„è®°å¿†é™ä½ä¼˜å…ˆçº§æˆ–åˆ é™¤
# - çŸ›ç›¾çš„è®°å¿†éœ€è¦äººå·¥å®¡æ ¸

def cleanup_stale_memories(store, namespace, max_age_days=90):
    """æ¸…ç†è¿‡æœŸè®°å¿†ï¼ˆç¤ºæ„ä»£ç ï¼‰"""
    from datetime import datetime, timedelta
    cutoff = datetime.now() - timedelta(days=max_age_days)

    items = store.search(namespace)
    for item in items:
        # æ£€æŸ¥åˆ›å»ºæ—¶é—´ï¼ˆéœ€è¦åœ¨ value ä¸­è®°å½•ï¼‰
        created = item.value.get("created_at")
        if created and datetime.fromisoformat(created) < cutoff:
            store.delete(namespace, item.key)
```

---

## 6. æœ€ä½³å®è·µæ€»ç»“

### çŸ­æœŸè®°å¿†

- ä¸€å®šè¦ä½¿ç”¨ `trim_messages` æˆ–æ€»ç»“æœºåˆ¶é˜²æ­¢æ¶ˆæ¯çˆ†ç‚¸
- System prompt è¦å§‹ç»ˆä¿ç•™ï¼ˆ`include_system=True`ï¼‰
- å·¥å…·è°ƒç”¨æ¶ˆæ¯å¯ä»¥é€‚å½“æ¸…ç†ä»¥å‡å°‘å™ªéŸ³

### é•¿æœŸè®°å¿†

- namespace è®¾è®¡è¦è€ƒè™‘å¤šç§Ÿæˆ·éš”ç¦»
- è¯­ä¹‰æœç´¢çš„ embedding æ¨¡å‹é€‰æ‹©å½±å“æ£€ç´¢è´¨é‡
- è®°å¿†æå–é€»è¾‘å»ºè®®ç”¨ LLM åšï¼ˆæ¯”æ­£åˆ™æå–æ›´é²æ£’ï¼‰
- å®šæœŸå®¡è®¡å’Œæ¸…ç†è¿‡æœŸè®°å¿†

### ä¸¤è€…åä½œ

- ä¸è¦åœ¨çŸ­æœŸè®°å¿†ä¸­å­˜å‚¨"åº”è¯¥æ˜¯é•¿æœŸçš„"æ•°æ®ï¼ˆå¦‚ç”¨æˆ·åå¥½ï¼‰
- ä¸è¦åœ¨é•¿æœŸè®°å¿†ä¸­å­˜å‚¨"åº”è¯¥æ˜¯çŸ­æœŸçš„"æ•°æ®ï¼ˆå¦‚å½“å‰ä»»åŠ¡ä¸Šä¸‹æ–‡ï¼‰
- å°†å…³é”®ä¿¡æ¯ä»çŸ­æœŸæå–åˆ°é•¿æœŸåº”åœ¨å¯¹è¯ç»“æŸæ—¶æˆ–å‘¨æœŸæ€§è¿›è¡Œ

---

## è¦ç‚¹å›é¡¾

| æ¦‚å¿µ | æœºåˆ¶ | å‰ç«¯ç±»æ¯” |
|------|------|---------|
| çŸ­æœŸè®°å¿† | Checkpoint (state) | `useState` / ç»„ä»¶ state |
| é•¿æœŸè®°å¿† | Store (namespace + key-value) | IndexedDB / åç«¯æ•°æ®åº“ |
| æ¶ˆæ¯è£å‰ª | `trim_messages` | è™šæ‹Ÿåˆ—è¡¨ï¼ˆåªæ¸²æŸ“å¯è§éƒ¨åˆ†ï¼‰ |
| æ¶ˆæ¯æ€»ç»“ | LLM summarize + `RemoveMessage` | åˆ—è¡¨åˆ†é¡µ + æ‘˜è¦ |
| è¯­ä¹‰æœç´¢ | Store + embedding index | Algolia / ElasticSearch |

---

## å…ˆä¿®ä¸ä¸‹ä¸€æ­¥

- **å…ˆä¿®**ï¼š[æŒä¹…åŒ–](/ai/langgraph/guide/persistence) | [Interrupts (HITL)](/ai/langgraph/guide/interrupts)
- **ä¸‹ä¸€æ­¥**ï¼š[Subgraphs å­å›¾](/ai/langgraph/guide/subgraphs) | [Time Travel](/ai/langgraph/guide/time-travel)
